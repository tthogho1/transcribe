#!/usr/bin/env python3
"""
S3ãƒã‚±ãƒƒãƒˆã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’å–å¾—ã—ã€DynamoDBã®transcribeå±æ€§ã‚’trueã«è¨­å®šã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ä½¿ç”¨æ–¹æ³•:
    python scripts/update_transcribe_status.py [OPTIONS]

ä¾‹:
    # å…¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å¯¾è±¡ã«å®Ÿè¡Œ
    python scripts/update_transcribe_status.py

    # ç‰¹å®šã®ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿å¯¾è±¡
    python scripts/update_transcribe_status.py --prefix audio4output/

    # ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³ãƒ¢ãƒ¼ãƒ‰ï¼ˆå®Ÿéš›ã«ã¯æ›´æ–°ã—ãªã„ï¼‰
    python scripts/update_transcribe_status.py --dry-run

    # ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’æŒ‡å®š
    python scripts/update_transcribe_status.py --batch-size 50
"""

import os
import sys
import argparse
import logging
from pathlib import Path
from typing import List, Optional
from dotenv import load_dotenv

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root / "src"))

# å¿…è¦ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from services.data.extract_text_fromS3 import S3JsonTextExtractor
from services.database.youtube_dynamodb_client import YouTubeDynamoDBClient

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


class TranscribeStatusUpdater:
    """S3ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‹ã‚‰DynamoDBã®transcribeå±æ€§ã‚’æ›´æ–°ã™ã‚‹ã‚¯ãƒ©ã‚¹"""

    def __init__(self, table_name: Optional[str] = None):
        """
        åˆæœŸåŒ–

        Args:
            table_name: DynamoDBãƒ†ãƒ¼ãƒ–ãƒ«åï¼ˆæŒ‡å®šã—ãªã„å ´åˆã¯ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—ï¼‰
        """
        # ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã¿
        load_dotenv()

        # S3ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
        self.s3_extractor = S3JsonTextExtractor()

        # DynamoDBã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
        if table_name is None:
            table_name = os.getenv("YOUTUBE_DYNAMODB_TABLE", "youtube_videos")

        self.dynamo_client = YouTubeDynamoDBClient(table_name)

        # è¨­å®š
        self.s3_bucket = os.getenv("S3_BUCKET_NAME")
        if not self.s3_bucket:
            raise ValueError("S3_BUCKET_NAMEç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")

        # AWSè¨­å®šæƒ…å ±ã‚’ãƒ­ã‚°å‡ºåŠ›
        aws_region = os.getenv("AWS_REGION", "ap-northeast-1")
        logger.info(f"ğŸ“¦ S3ãƒã‚±ãƒƒãƒˆå: {self.s3_bucket}")
        logger.info(f"ğŸŒ AWSãƒªãƒ¼ã‚¸ãƒ§ãƒ³: {aws_region}")
        logger.info(f"ğŸ—ƒï¸ DynamoDBãƒ†ãƒ¼ãƒ–ãƒ«: {table_name}")
        logger.info(f"ğŸ”§ è¨­å®šå®Œäº†: S3ã¨DynamoDBã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸ")

    def extract_video_id_from_key(self, s3_key: str) -> str:
        """
        S3ã‚­ãƒ¼ã‹ã‚‰ãƒ“ãƒ‡ã‚ªIDã‚’æŠ½å‡º

        Args:
            s3_key: S3ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚­ãƒ¼ (ä¾‹: "audio4output/Rkpqhl5l9d0_transcription.json")

        Returns:
            ãƒ“ãƒ‡ã‚ªID (ä¾‹: "Rkpqhl5l9d0")
        """
        # ãƒ•ã‚¡ã‚¤ãƒ«åã‚’å–å¾—
        filename = os.path.basename(s3_key)

        # æ‹¡å¼µå­ã‚’é™¤å»
        name_without_ext = os.path.splitext(filename)[0]

        # "_transcription"ã§åˆ†å‰²ã—ã¦æœ€åˆã®éƒ¨åˆ†ã‚’video_idã¨ã™ã‚‹
        if "_transcription" in name_without_ext:
            video_id = name_without_ext.split("_transcription")[0]
        else:
            # "_transcription"ãŒå«ã¾ã‚Œã¦ã„ãªã„å ´åˆã¯æ‹¡å¼µå­é™¤å»ã®ã¿ï¼ˆå¾Œæ–¹äº’æ›æ€§ï¼‰
            video_id = name_without_ext

        return video_id

    def get_s3_files(self, prefix: str = "") -> List[str]:
        """
        S3ãƒã‚±ãƒƒãƒˆã‹ã‚‰JSONãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’å–å¾—

        Args:
            prefix: æ¤œç´¢å¯¾è±¡ã®ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹

        Returns:
            S3ã‚­ãƒ¼ã®ãƒªã‚¹ãƒˆ
        """
        logger.info(f"ğŸ“‚ S3ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’å–å¾—ä¸­...")
        logger.info(f"   ãƒã‚±ãƒƒãƒˆ: {self.s3_bucket}")
        logger.info(f"   ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹: '{prefix}' (ç©ºã®å ´åˆã¯å…¨ãƒ•ã‚¡ã‚¤ãƒ«)")

        json_files = self.s3_extractor.list_json_files_in_bucket(self.s3_bucket, prefix)

        logger.info(f"âœ… ç™ºè¦‹ã—ãŸJSONãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(json_files)} ä»¶")
        if len(json_files) > 0:
            logger.info(
                f"   ä¾‹: {json_files[0]}"
                + (f", {json_files[1]}" if len(json_files) > 1 else "")
            )
        return json_files

    def update_transcribe_status(
        self, video_ids: List[str], batch_size: int = 25, dry_run: bool = False
    ) -> dict:
        """
        è¤‡æ•°ã®ãƒ“ãƒ‡ã‚ªIDã«å¯¾ã—ã¦transcribeå±æ€§ã‚’trueã«è¨­å®š

        Args:
            video_ids: ãƒ“ãƒ‡ã‚ªIDã®ãƒªã‚¹ãƒˆ
            batch_size: ãƒãƒƒãƒå‡¦ç†ã‚µã‚¤ã‚º
            dry_run: ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³ãƒ¢ãƒ¼ãƒ‰ï¼ˆå®Ÿéš›ã«ã¯æ›´æ–°ã—ãªã„ï¼‰

        Returns:
            å‡¦ç†çµæœã®çµ±è¨ˆ
        """
        stats = {
            "total": len(video_ids),
            "processed": 0,
            "updated": 0,
            "failed": 0,
            "already_transcribed": 0,
            "not_found": 0,
        }

        logger.info(f"transcribeå±æ€§ã®æ›´æ–°ã‚’é–‹å§‹... (å¯¾è±¡: {stats['total']}ä»¶)")
        if dry_run:
            logger.info("ğŸ” DRY RUN MODE - å®Ÿéš›ã®æ›´æ–°ã¯è¡Œã„ã¾ã›ã‚“")

        # ãƒãƒƒãƒå‡¦ç†
        for i in range(0, len(video_ids), batch_size):
            batch = video_ids[i : i + batch_size]
            logger.info(
                f"ãƒãƒƒãƒå‡¦ç†ä¸­ ({i+1}-{min(i+batch_size, len(video_ids))}/{len(video_ids)})"
            )

            for video_id in batch:
                stats["processed"] += 1

                try:
                    if dry_run:
                        # ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³ãƒ¢ãƒ¼ãƒ‰ï¼šãƒ¬ã‚³ãƒ¼ãƒ‰ã®å­˜åœ¨ç¢ºèªã®ã¿
                        record = self.dynamo_client.get_video_by_id(video_id)
                        if record:
                            if record.transcribed:
                                stats["already_transcribed"] += 1
                                logger.debug(f"âœ… {video_id}: ã™ã§ã«transcribed=true")
                            else:
                                stats["updated"] += 1
                                logger.info(
                                    f"ğŸ”„ {video_id}: transcribed=false â†’ true (DRY RUN)"
                                )
                        else:
                            stats["not_found"] += 1
                            logger.warning(
                                f"âš ï¸ {video_id}: DynamoDBãƒ¬ã‚³ãƒ¼ãƒ‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
                            )
                    else:
                        # å®Ÿéš›ã®æ›´æ–°å‡¦ç†
                        success = self.dynamo_client.update_transcribed_status(
                            video_id, True
                        )
                        if success:
                            stats["updated"] += 1
                            logger.info(f"âœ… {video_id}: transcribed=trueã«æ›´æ–°")
                        else:
                            stats["failed"] += 1
                            logger.error(f"âŒ {video_id}: æ›´æ–°ã«å¤±æ•—")

                except Exception as e:
                    stats["failed"] += 1
                    logger.error(f"âŒ {video_id}: ã‚¨ãƒ©ãƒ¼ - {e}")
                    continue

        return stats

    def run_update(
        self, prefix: str = "", batch_size: int = 25, dry_run: bool = False
    ) -> dict:
        """
        ãƒ¡ã‚¤ãƒ³å‡¦ç†ï¼šS3ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’å–å¾—ã—ã¦DynamoDBã‚’æ›´æ–°

        Args:
            prefix: S3æ¤œç´¢ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹
            batch_size: ãƒãƒƒãƒã‚µã‚¤ã‚º
            dry_run: ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³ãƒ¢ãƒ¼ãƒ‰

        Returns:
            å‡¦ç†çµæœã®çµ±è¨ˆ
        """
        try:
            # 1. S3ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’å–å¾—
            s3_files = self.get_s3_files(prefix)

            if not s3_files:
                logger.warning("å¯¾è±¡ã¨ãªã‚‹JSONãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                return {"total": 0, "processed": 0, "updated": 0, "failed": 0}

            # 2. ãƒ“ãƒ‡ã‚ªIDã‚’æŠ½å‡º
            video_ids = []
            for s3_key in s3_files:
                video_id = self.extract_video_id_from_key(s3_key)
                video_ids.append(video_id)
                logger.debug(f"S3ã‚­ãƒ¼: {s3_key} â†’ ãƒ“ãƒ‡ã‚ªID: {video_id}")

            logger.info(f"æŠ½å‡ºã—ãŸãƒ“ãƒ‡ã‚ªIDæ•°: {len(video_ids)}")

            # 3. DynamoDBã‚’æ›´æ–°
            stats = self.update_transcribe_status(video_ids, batch_size, dry_run)

            return stats

        except Exception as e:
            logger.error(f"å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            raise


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    parser = argparse.ArgumentParser(
        description="S3ãƒã‚±ãƒƒãƒˆã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’å–å¾—ã—ã€DynamoDBã®transcribeå±æ€§ã‚’trueã«è¨­å®š"
    )

    parser.add_argument(
        "--prefix",
        type=str,
        default="",
        help="S3æ¤œç´¢ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ (ä¾‹: audio4output/)",
    )

    parser.add_argument(
        "--batch-size", type=int, default=25, help="ãƒãƒƒãƒå‡¦ç†ã‚µã‚¤ã‚º (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 25)"
    )

    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³ãƒ¢ãƒ¼ãƒ‰ï¼ˆå®Ÿéš›ã®æ›´æ–°ã¯è¡Œã‚ãªã„ï¼‰",
    )

    parser.add_argument(
        "--table-name",
        type=str,
        help="DynamoDBãƒ†ãƒ¼ãƒ–ãƒ«åï¼ˆæŒ‡å®šã—ãªã„å ´åˆã¯ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—ï¼‰",
    )

    parser.add_argument(
        "--log-level",
        choices=["DEBUG", "INFO", "WARNING", "ERROR"],
        default="INFO",
        help="ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«",
    )

    parser.add_argument(
        "--show-bucket",
        action="store_true",
        help="ç¾åœ¨ã®S3ãƒã‚±ãƒƒãƒˆè¨­å®šã‚’è¡¨ç¤ºã—ã¦çµ‚äº†",
    )

    args = parser.parse_args()

    # ãƒã‚±ãƒƒãƒˆæƒ…å ±è¡¨ç¤ºã‚ªãƒ—ã‚·ãƒ§ãƒ³
    if args.show_bucket:
        show_bucket_info()
        return

    # ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«è¨­å®š
    logging.getLogger().setLevel(getattr(logging, args.log_level))

    try:
        # ç’°å¢ƒå¤‰æ•°ãƒã‚§ãƒƒã‚¯
        load_dotenv()
        required_env_vars = [
            "S3_BUCKET_NAME",
            "AWS_ACCESS_KEY_ID",
            "AWS_SECRET_ACCESS_KEY",
        ]
        missing_vars = [var for var in required_env_vars if not os.getenv(var)]

        if missing_vars:
            logger.error(f"å¿…è¦ãªç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“: {missing_vars}")
            logger.error("ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã®.envãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„")
            sys.exit(1)

        # ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ã‚¿ãƒ¼åˆæœŸåŒ–
        updater = TranscribeStatusUpdater(args.table_name)

        # å‡¦ç†å®Ÿè¡Œ
        logger.info("=" * 60)
        logger.info("ğŸš€ transcribeå±æ€§æ›´æ–°å‡¦ç†ã‚’é–‹å§‹")
        logger.info(f"ğŸ“¦ S3ãƒã‚±ãƒƒãƒˆ: {updater.s3_bucket}")
        logger.info(f"ğŸ“‚ ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹: '{args.prefix}' (ç©ºã®å ´åˆã¯å…¨ãƒ•ã‚¡ã‚¤ãƒ«)")
        logger.info(f"ğŸ“Š ãƒãƒƒãƒã‚µã‚¤ã‚º: {args.batch_size}")
        logger.info(f"ğŸ” ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³ãƒ¢ãƒ¼ãƒ‰: {args.dry_run}")
        logger.info("=" * 60)

        stats = updater.run_update(
            prefix=args.prefix, batch_size=args.batch_size, dry_run=args.dry_run
        )

        # çµæœè¡¨ç¤º
        logger.info("=" * 60)
        logger.info("âœ… å‡¦ç†å®Œäº†")
        logger.info(f"å¯¾è±¡ä»¶æ•°: {stats['total']}")
        logger.info(f"å‡¦ç†æ¸ˆã¿: {stats['processed']}")
        logger.info(f"æ›´æ–°æ¸ˆã¿: {stats['updated']}")

        if stats.get("already_transcribed", 0) > 0:
            logger.info(f"æ—¢ã«transcribed=true: {stats['already_transcribed']}")

        if stats.get("not_found", 0) > 0:
            logger.warning(f"ãƒ¬ã‚³ãƒ¼ãƒ‰æœªç™ºè¦‹: {stats['not_found']}")

        if stats["failed"] > 0:
            logger.warning(f"å¤±æ•—: {stats['failed']}")

        logger.info("=" * 60)

        # çµ‚äº†ã‚³ãƒ¼ãƒ‰
        if stats["failed"] > 0:
            sys.exit(1)
        else:
            sys.exit(0)

    except KeyboardInterrupt:
        logger.info("\nå‡¦ç†ãŒä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
        sys.exit(1)
    except Exception as e:
        logger.error(f"äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        sys.exit(1)


def show_bucket_info():
    """ç¾åœ¨ã®S3ãƒã‚±ãƒƒãƒˆè¨­å®šã‚’è¡¨ç¤º"""
    load_dotenv()

    bucket_name = os.getenv("S3_BUCKET_NAME")
    aws_region = os.getenv("AWS_REGION", "ap-northeast-1")

    print("=" * 60)
    print("ğŸ“¦ ç¾åœ¨ã®S3è¨­å®š")
    print("=" * 60)
    print(f"ãƒã‚±ãƒƒãƒˆå: {bucket_name or 'âŒ æœªè¨­å®š'}")
    print(f"ãƒªãƒ¼ã‚¸ãƒ§ãƒ³: {aws_region}")
    print("=" * 60)

    if not bucket_name:
        print("âš ï¸ S3_BUCKET_NAMEç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        print("   .envãƒ•ã‚¡ã‚¤ãƒ«ã§S3_BUCKET_NAMEã‚’è¨­å®šã—ã¦ãã ã•ã„")


if __name__ == "__main__":
    main()
